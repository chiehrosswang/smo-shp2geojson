}
traffic.cols <- c("YEAR","SITEID","AADT","AADTT")
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
}
}
}
#################################################################################
#################################################################################
###                                                                           ###
### Developed by Chieh (Ross) Wang                                            ###
### School of Civil and Enviornmental Engineering                             ###
### Georgia Institute of Technology                                           ###
###                                                                           ###
### Purpose: To scrape GDOT traffic count data from GDOT's website @          ###
###          http://geocounts.com/gdot/ and save into database tables         ###
###          for research applications                                        ###
###                                                                           ###
#################################################################################
#################################################################################
library(scrapeR)
# Define an empty variable to hold the output results
siteInfo <- NULL
traffic <- NULL
# Generate a list of GA County FIPs (from 001 to 321 excluding 041 and 203)
cntyfips <- seq(1,321,2)
notCnty <- c(41, 203)
cntyfips <- cntyfips[! cntyfips %in% notCnty]
for (i in 1:1){#:length(cntyfips)) {
for (j in 183:183){#:9999) {
# Site type: permanent or portable
SITE_TYPE <- "PERMANENT"
# SITE_TYPE <- "PORTABLE"
# SiteID for permanent sites: 3-digit countyfips + "-" + 4-digit counter id (e.g., 001-0203)
# SiteID for portable sites: 3-digit countyfips + 4-digit counter id (e.g., 2110129)
if (SITE_TYPE == "PERMANENT") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),"-",sprintf("%04d",j))
} else if (SITE_TYPE == "PORTABLE") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),sprintf("%04d",j))
}
# Generate the site-specific URL and parse its content
url = paste0("http://trafficserver.transmetric.com/gdot-prod/tcdb.jsp?siteid=",siteid)
txt <- htmlTreeParse(url)[3]
if (!grepl("Error encountered",txt)) {
sourceCode <- scrape(url)
TC.tables <- readHTMLTable(sourceCode[[1]],header=FALSE)
# Referencing Tab > About Station Table
stationInfo <- data.frame(TC.tables[2])[,1:2]
# Annual Statistics Tab > Volume
aadt <- data.frame(TC.tables[5])[,1:2]
colnames(aadt) <- c("Year","AADT")
# Annual Statistics Tab > Trucks
aadtt <- data.frame(TC.tables[6])[,1:2]
colnames(aadtt) <- c("Year","AADTT")
# Annual Statistics Tab > Key Annual Trends (including K and D factors)
trends <- data.frame(TC.tables[7])
# Raw Data Tab
rawData <- data.frame(TC.tables[8])
# Extract information from stationInfo
SITE_ID <- toString(stationInfo[1,2])
CNTY_NAME <- toString(stationInfo[2,2])
FUNC_CLASS <- toString(stationInfo[5,2])
RCLINK <- head(strsplit(toString(stationInfo[12,2]),split=" ")[[1]][1])
ROUTE_TYPE <- as.numeric(strsplit(RCLINK,split='')[[1]][4])
ROUTE_NUMBER <- substr(toString(stationInfo[8,2]),1,4)
SUFFIX <- substr(toString(stationInfo[8,2]),5,6)
ROUTE_NUMBER2 <- substr(toString(stationInfo[9,2]),1,4)
SUFFIX2 <- substr(toString(stationInfo[9,2]),5,6)
ROUTE_NUMBER3 <- substr(toString(stationInfo[10,2]),1,4)
SUFFIX3 <- substr(toString(stationInfo[10,2]),5,6)
ROUTE_NUMBER4 <- substr(toString(stationInfo[11,2]),1,4)
SUFFIX4 <- substr(toString(stationInfo[11,2]),5,6)
SEG_FROM <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[2])
SEG_TO <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[4])
LAT <- as.numeric(head(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[1])
LONG <- as.numeric(tail(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[2])
# Creating two tables that can be joint using the 7-digit siteid
# 1. siteInfo table to store all site-related information
# 2. traffic table to store all traffic counts of the site
# siteInfo table
output <- c(SITE_ID, CNTY_NAME, sprintf("%03d",cntyfips[i]), sprintf("%04d",j), SITE_TYPE, FUNC_CLASS, RCLINK, ROUTE_TYPE, ROUTE_NUMBER, SUFFIX, SEG_FROM, SEG_TO, LAT, LONG, ROUTE_NUMBER2, SUFFIX2, ROUTE_NUMBER3, SUFFIX3, ROUTE_NUMBER4, SUFFIX4)
sites <- as.matrix(t(output))
sites.cols <- c("SITEID","CNTYNAME","CNTYFIPS","SITE","SITE_TYPE","FUNC_CLASS","RCLINK","ROUTE_TYPE","ROUTE_NUMBER","SUFFIX","SEG_FROM","SEG_TO","LAT","LONG","ROUTE_NUMBER2","SUFFIX2","ROUTE_NUMBER3","SUFFIX3","ROUTE_NUMBER4","SUFFIX4")
write.table(sites,paste0(format(Sys.Date(),"%Y%m%d"),"_siteInfo.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
for (y in 1:length(aadt[,1])) {
r <- which(aadtt[,1]==levels(droplevels(aadt[y,1])))
truck <- ifelse(length(r)==1, as.numeric(levels(droplevels(aadtt[r,2]))), '')
entry <- c(toString(aadt[y,1]), siteid, as.numeric(levels(droplevels(aadt[y,2]))), truck)
traffic <- rbind(traffic,entry)
}
traffic.cols <- c("YEAR","SITEID","AADT","AADTT")
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
}
}
}
#################################################################################
#################################################################################
###                                                                           ###
### Developed by Chieh (Ross) Wang                                            ###
### School of Civil and Enviornmental Engineering                             ###
### Georgia Institute of Technology                                           ###
###                                                                           ###
### Purpose: To scrape GDOT traffic count data from GDOT's website @          ###
###          http://geocounts.com/gdot/ and save into database tables         ###
###          for research applications                                        ###
###                                                                           ###
#################################################################################
#################################################################################
library(scrapeR)
# Define an empty variable to hold the output results
siteInfo <- NULL
traffic <- NULL
# Generate a list of GA County FIPs (from 001 to 321 excluding 041 and 203)
cntyfips <- seq(1,321,2)
notCnty <- c(41, 203)
cntyfips <- cntyfips[! cntyfips %in% notCnty]
for (i in 1:1){#:length(cntyfips)) {
for (j in 183:183){#:9999) {
# Site type: permanent or portable
SITE_TYPE <- "PERMANENT"
# SITE_TYPE <- "PORTABLE"
# SiteID for permanent sites: 3-digit countyfips + "-" + 4-digit counter id (e.g., 001-0203)
# SiteID for portable sites: 3-digit countyfips + 4-digit counter id (e.g., 2110129)
if (SITE_TYPE == "PERMANENT") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),"-",sprintf("%04d",j))
} else if (SITE_TYPE == "PORTABLE") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),sprintf("%04d",j))
}
# Generate the site-specific URL and parse its content
url = paste0("http://trafficserver.transmetric.com/gdot-prod/tcdb.jsp?siteid=",siteid)
txt <- htmlTreeParse(url)[3]
if (!grepl("Error encountered",txt)) {
sourceCode <- scrape(url)
TC.tables <- readHTMLTable(sourceCode[[1]],header=FALSE)
# Referencing Tab > About Station Table
stationInfo <- data.frame(TC.tables[2])[,1:2]
# Annual Statistics Tab > Volume
aadt <- data.frame(TC.tables[5])[,1:2]
colnames(aadt) <- c("Year","AADT")
# Annual Statistics Tab > Trucks
aadtt <- data.frame(TC.tables[6])[,1:2]
colnames(aadtt) <- c("Year","AADTT")
# Annual Statistics Tab > Key Annual Trends (including K and D factors)
trends <- data.frame(TC.tables[7])
# Raw Data Tab
rawData <- data.frame(TC.tables[8])
# Extract information from stationInfo
SITE_ID <- toString(stationInfo[1,2])
CNTY_NAME <- toString(stationInfo[2,2])
FUNC_CLASS <- toString(stationInfo[5,2])
RCLINK <- head(strsplit(toString(stationInfo[12,2]),split=" ")[[1]][1])
ROUTE_TYPE <- as.numeric(strsplit(RCLINK,split='')[[1]][4])
ROUTE_NUMBER <- substr(toString(stationInfo[8,2]),1,4)
SUFFIX <- substr(toString(stationInfo[8,2]),5,6)
ROUTE_NUMBER2 <- substr(toString(stationInfo[9,2]),1,4)
SUFFIX2 <- substr(toString(stationInfo[9,2]),5,6)
ROUTE_NUMBER3 <- substr(toString(stationInfo[10,2]),1,4)
SUFFIX3 <- substr(toString(stationInfo[10,2]),5,6)
ROUTE_NUMBER4 <- substr(toString(stationInfo[11,2]),1,4)
SUFFIX4 <- substr(toString(stationInfo[11,2]),5,6)
SEG_FROM <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[2])
SEG_TO <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[4])
LAT <- as.numeric(head(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[1])
LONG <- as.numeric(tail(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[2])
# Creating two tables that can be joint using the 7-digit siteid
# 1. siteInfo table to store all site-related information
# 2. traffic table to store all traffic counts of the site
# siteInfo table
output <- c(SITE_ID, CNTY_NAME, sprintf("%03d",cntyfips[i]), sprintf("%04d",j), SITE_TYPE, FUNC_CLASS, RCLINK, ROUTE_TYPE, ROUTE_NUMBER, SUFFIX, SEG_FROM, SEG_TO, LAT, LONG, ROUTE_NUMBER2, SUFFIX2, ROUTE_NUMBER3, SUFFIX3, ROUTE_NUMBER4, SUFFIX4)
sites <- as.matrix(t(output))
# sites.cols <- c("SITEID","CNTYNAME","CNTYFIPS","SITE","SITE_TYPE","FUNC_CLASS","RCLINK","ROUTE_TYPE","ROUTE_NUMBER","SUFFIX","SEG_FROM","SEG_TO","LAT","LONG","ROUTE_NUMBER2","SUFFIX2","ROUTE_NUMBER3","SUFFIX3","ROUTE_NUMBER4","SUFFIX4")
write.table(sites,paste0(format(Sys.Date(),"%Y%m%d"),"_siteInfo.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
for (y in 1:length(aadt[,1])) {
r <- which(aadtt[,1]==levels(droplevels(aadt[y,1])))
truck <- ifelse(length(r)==1, as.numeric(levels(droplevels(aadtt[r,2]))), '')
entry <- c(toString(aadt[y,1]), siteid, as.numeric(levels(droplevels(aadt[y,2]))), truck)
traffic <- rbind(traffic,entry)
}
# traffic.cols <- c("YEAR","SITEID","AADT","AADTT")
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
}
}
}
# Output files will be saved here:
shell.exec(getwd())
#################################################################################
#################################################################################
###                                                                           ###
### Developed by Chieh (Ross) Wang                                            ###
### School of Civil and Enviornmental Engineering                             ###
### Georgia Institute of Technology                                           ###
###                                                                           ###
### Purpose: To scrape GDOT traffic count data from GDOT's website @          ###
###          http://geocounts.com/gdot/ and save into database tables         ###
###          for research applications                                        ###
###                                                                           ###
#################################################################################
#################################################################################
library(scrapeR)
# Define an empty variable to hold the output results
siteInfo <- NULL
traffic <- NULL
# Generate a list of GA County FIPs (from 001 to 321 excluding 041 and 203)
cntyfips <- seq(1,321,2)
notCnty <- c(41, 203)
cntyfips <- cntyfips[! cntyfips %in% notCnty]
for (i in 1:1){#:length(cntyfips)) {
for (j in 183:185){#:9999) {
# Site type: permanent or portable
SITE_TYPE <- "PERMANENT"
# SITE_TYPE <- "PORTABLE"
# SiteID for permanent sites: 3-digit countyfips + "-" + 4-digit counter id (e.g., 001-0203)
# SiteID for portable sites: 3-digit countyfips + 4-digit counter id (e.g., 2110129)
if (SITE_TYPE == "PERMANENT") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),"-",sprintf("%04d",j))
} else if (SITE_TYPE == "PORTABLE") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),sprintf("%04d",j))
}
# Generate the site-specific URL and parse its content
url = paste0("http://trafficserver.transmetric.com/gdot-prod/tcdb.jsp?siteid=",siteid)
txt <- htmlTreeParse(url)[3]
if (!grepl("Error encountered",txt)) {
sourceCode <- scrape(url)
TC.tables <- readHTMLTable(sourceCode[[1]],header=FALSE)
# Referencing Tab > About Station Table
stationInfo <- data.frame(TC.tables[2])[,1:2]
# Annual Statistics Tab > Volume
aadt <- data.frame(TC.tables[5])[,1:2]
colnames(aadt) <- c("Year","AADT")
# Annual Statistics Tab > Trucks
aadtt <- data.frame(TC.tables[6])[,1:2]
colnames(aadtt) <- c("Year","AADTT")
# Annual Statistics Tab > Key Annual Trends (including K and D factors)
trends <- data.frame(TC.tables[7])
# Raw Data Tab
rawData <- data.frame(TC.tables[8])
# Extract information from stationInfo
SITE_ID <- toString(stationInfo[1,2])
CNTY_NAME <- toString(stationInfo[2,2])
FUNC_CLASS <- toString(stationInfo[5,2])
RCLINK <- head(strsplit(toString(stationInfo[12,2]),split=" ")[[1]][1])
ROUTE_TYPE <- as.numeric(strsplit(RCLINK,split='')[[1]][4])
ROUTE_NUMBER <- substr(toString(stationInfo[8,2]),1,4)
SUFFIX <- substr(toString(stationInfo[8,2]),5,6)
ROUTE_NUMBER2 <- substr(toString(stationInfo[9,2]),1,4)
SUFFIX2 <- substr(toString(stationInfo[9,2]),5,6)
ROUTE_NUMBER3 <- substr(toString(stationInfo[10,2]),1,4)
SUFFIX3 <- substr(toString(stationInfo[10,2]),5,6)
ROUTE_NUMBER4 <- substr(toString(stationInfo[11,2]),1,4)
SUFFIX4 <- substr(toString(stationInfo[11,2]),5,6)
SEG_FROM <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[2])
SEG_TO <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[4])
LAT <- as.numeric(head(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[1])
LONG <- as.numeric(tail(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[2])
# Creating two tables that can be joint using the 7-digit siteid
# 1. siteInfo table to store all site-related information
# 2. traffic table to store all traffic counts of the site
# siteInfo table
output <- c(SITE_ID, CNTY_NAME, sprintf("%03d",cntyfips[i]), sprintf("%04d",j), SITE_TYPE, FUNC_CLASS, RCLINK, ROUTE_TYPE, ROUTE_NUMBER, SUFFIX, SEG_FROM, SEG_TO, LAT, LONG, ROUTE_NUMBER2, SUFFIX2, ROUTE_NUMBER3, SUFFIX3, ROUTE_NUMBER4, SUFFIX4)
sites <- as.matrix(t(output))
# sites.cols <- c("SITEID","CNTYNAME","CNTYFIPS","SITE","SITE_TYPE","FUNC_CLASS","RCLINK","ROUTE_TYPE","ROUTE_NUMBER","SUFFIX","SEG_FROM","SEG_TO","LAT","LONG","ROUTE_NUMBER2","SUFFIX2","ROUTE_NUMBER3","SUFFIX3","ROUTE_NUMBER4","SUFFIX4")
write.table(sites,paste0(format(Sys.Date(),"%Y%m%d"),"_siteInfo.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
for (y in 1:length(aadt[,1])) {
r <- which(aadtt[,1]==levels(droplevels(aadt[y,1])))
truck <- ifelse(length(r)==1, as.numeric(levels(droplevels(aadtt[r,2]))), '')
entry <- c(toString(aadt[y,1]), siteid, as.numeric(levels(droplevels(aadt[y,2]))), truck)
traffic <- rbind(traffic,entry)
}
traffic.cols <- c("YEAR","SITEID","AADT","AADTT")
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=TRUE,row.names=FALSE)
}
}
}
# Output files will be saved here:
shell.exec(getwd())
#################################################################################
#################################################################################
###                                                                           ###
### Developed by Chieh (Ross) Wang                                            ###
### School of Civil and Enviornmental Engineering                             ###
### Georgia Institute of Technology                                           ###
###                                                                           ###
### Purpose: To scrape GDOT traffic count data from GDOT's website @          ###
###          http://geocounts.com/gdot/ and save into database tables         ###
###          for research applications                                        ###
###                                                                           ###
#################################################################################
#################################################################################
library(scrapeR)
# Define an empty variable to hold the output results
siteInfo <- NULL
traffic <- NULL
# Generate a list of GA County FIPs (from 001 to 321 excluding 041 and 203)
cntyfips <- seq(1,321,2)
notCnty <- c(41, 203)
cntyfips <- cntyfips[! cntyfips %in% notCnty]
for (i in 1:1){#:length(cntyfips)) {
for (j in 183:185){#:9999) {
# Site type: permanent or portable
SITE_TYPE <- "PERMANENT"
# SITE_TYPE <- "PORTABLE"
# SiteID for permanent sites: 3-digit countyfips + "-" + 4-digit counter id (e.g., 001-0203)
# SiteID for portable sites: 3-digit countyfips + 4-digit counter id (e.g., 2110129)
if (SITE_TYPE == "PERMANENT") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),"-",sprintf("%04d",j))
} else if (SITE_TYPE == "PORTABLE") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),sprintf("%04d",j))
}
# Generate the site-specific URL and parse its content
url = paste0("http://trafficserver.transmetric.com/gdot-prod/tcdb.jsp?siteid=",siteid)
txt <- htmlTreeParse(url)[3]
if (!grepl("Error encountered",txt)) {
sourceCode <- scrape(url)
TC.tables <- readHTMLTable(sourceCode[[1]],header=FALSE)
# Referencing Tab > About Station Table
stationInfo <- data.frame(TC.tables[2])[,1:2]
# Annual Statistics Tab > Volume
aadt <- data.frame(TC.tables[5])[,1:2]
colnames(aadt) <- c("Year","AADT")
# Annual Statistics Tab > Trucks
aadtt <- data.frame(TC.tables[6])[,1:2]
colnames(aadtt) <- c("Year","AADTT")
# Annual Statistics Tab > Key Annual Trends (including K and D factors)
trends <- data.frame(TC.tables[7])
# Raw Data Tab
rawData <- data.frame(TC.tables[8])
# Extract information from stationInfo
SITE_ID <- toString(stationInfo[1,2])
CNTY_NAME <- toString(stationInfo[2,2])
FUNC_CLASS <- toString(stationInfo[5,2])
RCLINK <- head(strsplit(toString(stationInfo[12,2]),split=" ")[[1]][1])
ROUTE_TYPE <- as.numeric(strsplit(RCLINK,split='')[[1]][4])
ROUTE_NUMBER <- substr(toString(stationInfo[8,2]),1,4)
SUFFIX <- substr(toString(stationInfo[8,2]),5,6)
ROUTE_NUMBER2 <- substr(toString(stationInfo[9,2]),1,4)
SUFFIX2 <- substr(toString(stationInfo[9,2]),5,6)
ROUTE_NUMBER3 <- substr(toString(stationInfo[10,2]),1,4)
SUFFIX3 <- substr(toString(stationInfo[10,2]),5,6)
ROUTE_NUMBER4 <- substr(toString(stationInfo[11,2]),1,4)
SUFFIX4 <- substr(toString(stationInfo[11,2]),5,6)
SEG_FROM <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[2])
SEG_TO <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[4])
LAT <- as.numeric(head(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[1])
LONG <- as.numeric(tail(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[2])
# Creating two tables that can be joint using the 7-digit siteid
# 1. siteInfo table to store all site-related information
# 2. traffic table to store all traffic counts of the site
# siteInfo table
output <- c(SITE_ID, CNTY_NAME, sprintf("%03d",cntyfips[i]), sprintf("%04d",j), SITE_TYPE, FUNC_CLASS, RCLINK, ROUTE_TYPE, ROUTE_NUMBER, SUFFIX, SEG_FROM, SEG_TO, LAT, LONG, ROUTE_NUMBER2, SUFFIX2, ROUTE_NUMBER3, SUFFIX3, ROUTE_NUMBER4, SUFFIX4)
sites <- as.matrix(t(output))
write.table(sites,paste0(format(Sys.Date(),"%Y%m%d"),"_siteInfo.csv"),append=TRUE,sep=",",col.names=FALSE,row.names=FALSE)
for (y in 1:length(aadt[,1])) {
r <- which(aadtt[,1]==levels(droplevels(aadt[y,1])))
truck <- ifelse(length(r)==1, as.numeric(levels(droplevels(aadtt[r,2]))), '')
entry <- c(toString(aadt[y,1]), siteid, as.numeric(levels(droplevels(aadt[y,2]))), truck)
traffic <- rbind(traffic,entry)
}
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=FALSE,row.names=FALSE)
}
}
}
# Output files will be saved here:
shell.exec(getwd())
#################################################################################
#################################################################################
###                                                                           ###
### Developed by Chieh (Ross) Wang                                            ###
### School of Civil and Enviornmental Engineering                             ###
### Georgia Institute of Technology                                           ###
###                                                                           ###
### Purpose: To scrape GDOT traffic count data from GDOT's website @          ###
###          http://geocounts.com/gdot/ and save into database tables         ###
###          for research applications                                        ###
###                                                                           ###
#################################################################################
#################################################################################
library(scrapeR)
# Generate a list of GA County FIPs (from 001 to 321 excluding 041 and 203)
cntyfips <- seq(1,321,2)
notCnty <- c(41, 203)
cntyfips <- cntyfips[! cntyfips %in% notCnty]
for (i in 1:1){#:length(cntyfips)) {
for (j in 183:185){#:9999) {
# Site type: permanent or portable
SITE_TYPE <- "PERMANENT"
# SITE_TYPE <- "PORTABLE"
# SiteID for permanent sites: 3-digit countyfips + "-" + 4-digit counter id (e.g., 001-0203)
# SiteID for portable sites: 3-digit countyfips + 4-digit counter id (e.g., 2110129)
if (SITE_TYPE == "PERMANENT") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),"-",sprintf("%04d",j))
} else if (SITE_TYPE == "PORTABLE") {
siteid <- paste0(sprintf("%03d",cntyfips[i]),sprintf("%04d",j))
}
# Generate the site-specific URL and parse its content
url = paste0("http://trafficserver.transmetric.com/gdot-prod/tcdb.jsp?siteid=",siteid)
txt <- htmlTreeParse(url)[3]
if (!grepl("Error encountered",txt)) {
sourceCode <- scrape(url)
TC.tables <- readHTMLTable(sourceCode[[1]],header=FALSE)
# Referencing Tab > About Station Table
stationInfo <- data.frame(TC.tables[2])[,1:2]
# Annual Statistics Tab > Volume
aadt <- data.frame(TC.tables[5])[,1:2]
colnames(aadt) <- c("Year","AADT")
# Annual Statistics Tab > Trucks
aadtt <- data.frame(TC.tables[6])[,1:2]
colnames(aadtt) <- c("Year","AADTT")
# Annual Statistics Tab > Key Annual Trends (including K and D factors)
trends <- data.frame(TC.tables[7])
# Raw Data Tab
rawData <- data.frame(TC.tables[8])
# Extract information from stationInfo
SITE_ID <- toString(stationInfo[1,2])
CNTY_NAME <- toString(stationInfo[2,2])
FUNC_CLASS <- toString(stationInfo[5,2])
RCLINK <- head(strsplit(toString(stationInfo[12,2]),split=" ")[[1]][1])
ROUTE_TYPE <- as.numeric(strsplit(RCLINK,split='')[[1]][4])
ROUTE_NUMBER <- substr(toString(stationInfo[8,2]),1,4)
SUFFIX <- substr(toString(stationInfo[8,2]),5,6)
ROUTE_NUMBER2 <- substr(toString(stationInfo[9,2]),1,4)
SUFFIX2 <- substr(toString(stationInfo[9,2]),5,6)
ROUTE_NUMBER3 <- substr(toString(stationInfo[10,2]),1,4)
SUFFIX3 <- substr(toString(stationInfo[10,2]),5,6)
ROUTE_NUMBER4 <- substr(toString(stationInfo[11,2]),1,4)
SUFFIX4 <- substr(toString(stationInfo[11,2]),5,6)
SEG_FROM <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[2])
SEG_TO <- as.numeric(head(strsplit(toString(stationInfo[13,2]),split=" ")[[1]])[4])
LAT <- as.numeric(head(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[1])
LONG <- as.numeric(tail(strsplit(toString(stationInfo[14,2]),split=",")[[1]])[2])
# Creating two tables that can be joint using the 7-digit siteid
# 1. siteInfo table to store all site-related information
# 2. traffic table to store all traffic counts of the site
# siteInfo table
output <- c(SITE_ID, CNTY_NAME, sprintf("%03d",cntyfips[i]), sprintf("%04d",j), SITE_TYPE, FUNC_CLASS, RCLINK, ROUTE_TYPE, ROUTE_NUMBER, SUFFIX, SEG_FROM, SEG_TO, LAT, LONG, ROUTE_NUMBER2, SUFFIX2, ROUTE_NUMBER3, SUFFIX3, ROUTE_NUMBER4, SUFFIX4)
sites <- as.matrix(t(output))
write.table(sites,paste0(format(Sys.Date(),"%Y%m%d"),"_siteInfo.csv"),append=TRUE,sep=",",col.names=FALSE,row.names=FALSE)
traffic <- NULL
for (y in 1:length(aadt[,1])) {
r <- which(aadtt[,1]==levels(droplevels(aadt[y,1])))
truck <- ifelse(length(r)==1, as.numeric(levels(droplevels(aadtt[r,2]))), '')
entry <- c(toString(aadt[y,1]), siteid, as.numeric(levels(droplevels(aadt[y,2]))), truck)
traffic <- rbind(traffic,entry)
}
write.table(traffic,paste0(format(Sys.Date(),"%Y%m%d"),"_traffic.csv"),append=TRUE,sep=",",col.names=FALSE,row.names=FALSE)
}
}
}
# Output files will be saved here:
shell.exec(getwd())
install.packages("devtools")
devtools::install_github("rstudio/bookdown")
library(rgdal)
library(spdplyr)
library(geojsonio)
# Load shapefile
roads <- readOGR('./Data/road_status.shp', 'road_status')
summary(roads) #proj4string:[+proj=utm +zone=17 +datum=NAD83 +units=m ...
# Project layer to GCS (latlng)
roads.latlng <- spTransform(roads, CRS("+proj=longlat"))
summary(roads.latlng) #proj4string:[+proj=longlat +ellps=WGS84]
setwd("~/GitHub/SMO-shp2geojson")
setwd("~/GitHub/SMO-shp2geojson")
# Load shapefile
roads <- readOGR('./Data/road_status.shp', 'road_status')
summary(roads) #proj4string:[+proj=utm +zone=17 +datum=NAD83 +units=m ...
# Project layer to GCS (latlng)
roads.latlng <- spTransform(roads, CRS("+proj=longlat"))
summary(roads.latlng) #proj4string:[+proj=longlat +ellps=WGS84]
# Create a layer with active on Florida State
# Highway System roads (ROAD_STATU == "02")
roads.latlng_02 <- roads.latlng %>%
filter(ROAD_STATU == "02")
?spTransform
?spTransform
?geojson_json
road_status_02 <- geojson_json(roads.latlng_02, digits = 15) # convert shp to GeoJSON
geojson_write(road_status_02, file = "./road_status_02.geojson") # write file
road_status_02_07_09 <- geojson_json(roads.latlng_02_07_09, digits = 15) # convert shp to GeoJSON
# Create a layer with active on SHS ("02"), active
# exclusive ("07"), and active off SHS ("09") roads
roads.latlng_02_07_09 <- roads.latlng %>%
filter(ROAD_STATU == "02" |
ROAD_STATU == "07" |
ROAD_STATU == "09")
road_status_02_07_09 <- geojson_json(roads.latlng_02_07_09, digits = 15) # convert shp to GeoJSON
geojson_write(road_status_02_07_09, file = "./road_status_02_07_09.geojson") # write file
road_status_02 <- geojson_json(roads.latlng_02, digits = 8) # convert shp to GeoJSON
geojson_write(road_status_02, file = "./road_status_02.geojson") # write file
road_status_02_07_09 <- geojson_json(roads.latlng_02_07_09, digits = 8) # convert shp to GeoJSON
geojson_write(road_status_02_07_09, file = "./road_status_02_07_09.geojson") # write file
head(road_status_02)
?geojson_write
geojson_write(road_status_02, file = "./road_status_02.geojson", precision = 15) # write file
geojson_write(road_status_02, file = "./road_status_02.geojson", precision = 15) # write file
poly <- list(c(-114.345703125,39.436192999314095),
c(-114.345703125,43.45291889355468),
c(-106.61132812499999,43.45291889355468),
c(-106.61132812499999,39.436192999314095),
c(-114.345703125,39.436192999314095))
geojson_write(poly, geometry = "polygon")
### named list
mylist <- list(list(latitude=30, longitude=120, marker="red"),
list(latitude=30, longitude=130, marker="blue"))
geojson_write(mylist)
poly <- list(c(-114.345703125,39.436192999314095),
c(-114.345703125,43.45291889355468),
c(-106.61132812499999,43.45291889355468),
c(-106.61132812499999,39.436192999314095),
c(-114.345703125,39.436192999314095))
geojson_write(poly, geometry = "polygon")
geojson_write(road_status_02) # write file
geojson_write(road_status_02, file = "./GeoJSON/road_status_02.geojson", digits = 15) # write file
geojson_write(road_status_02_07_09, file = "./GeoJSON/road_status_02_07_09.geojson", digits = 15) # write file
